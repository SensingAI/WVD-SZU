# WVD-SZU (ICME2023)ï¼šNeed a dog seeing eye? A Walk Viewpoint Dataset for Freespace Detection in Unstructured Environments
<img src="https://www.szu.edu.cn/images/logo_03.png" width="325" > <img src="http://iip.szu.edu.cn/uploads/admin/202010/5f866c5e7eb7e.jpg" width="415" height="95">

Wenbin Zou<sup>1,2,3</sup>, Guoguang Hua, Guangxu Chen, Zaiyue He, Guangli Liu, Pengfei Chen, Yuyang Li, Huakun Li, Lei Zheng, Shishun Tian <br>

  1. [Shenzhen University](https://www.szu.edu.cn/)  2. [Guangdong KLIIP](http://iip.szu.edu.cn/) 3. SenSingAI   <br>

  [Website] [Paper] [[Github](https://github.com/SensingAI/WVD-SZU/)]


## Updates
* 29/04/2023 `v1.0 release`

## Overview
**Freespace Detection** (FD) is crucial for robust and safe autonomous navigation. However, existing datasets usually concentrate on structure road environments. The FD in unstructured environments, e.g., walk assistance for the visually-impaired, has been rarely investigated. In this paper, We propose a novel dataset called the **Walk Viewpoint Dataset (WVD)**. Different from the previous datasets, we focus on the walk viewpoint, where FD can provide the potential for improving the walking of visually impaired people. The target regions of WVD are annotated with **20 categories** by fine-grained labels, which consist of **3,737** images and depth images. Moreover, we propose a new annotation hierarchy, which allows different degrees of complexity and creates opportunities for new training methods. Finally, our study provides the statistical analysis of label characteristics and baseline analysis, which demonstrates its distinction compared to previous datasets.

<img src="https://github.com/SensingAI/WVD-SZU/raw/main/images/Examples_00.jpg" width="925" >

## Folder Structure

## Download Link on BaiDu Cloud
Link:

PassWord:

## Annotated Data

## Benchmarks

## Citation


## License
All datasets and code on this page are copyright by us and published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License.








